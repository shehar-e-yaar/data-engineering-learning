{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97efa66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Data : ['Fatima', 'Ali', 'Umar']\n"
     ]
    }
   ],
   "source": [
    "data=['FAtima','AlI','umar']\n",
    "cleaned_data=[]\n",
    "for f in data:\n",
    "    data=f.strip().capitalize()\n",
    "    cleaned_data.append(data)\n",
    "print(\"Cleaned Data :\",cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "781a8e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ALi', '19', 'LaHore']\n",
      "['USmAn', '20', 'IslamAbad ']\n",
      "['RafEEq', '18', 'LahorE']\n"
     ]
    }
   ],
   "source": [
    "#Reading CSV File\n",
    "import csv\n",
    "cleanedcsv=[]\n",
    "with open('Dataset.csv',\"r\") as f:\n",
    "    reader=csv.reader(f)\n",
    "    next(reader)  # Skip header row if present\n",
    "    for f in reader:\n",
    "        print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ed553bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is Muhammad Sheheryar.This is a new line added to the text file.\n",
      "\n",
      "This is a new line added to the text file.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Reading Text File\n",
    "f=open('Dataset.txt',\"r\")\n",
    "for i in f:\n",
    "    print(i)\n",
    "f=open('Dataset.txt',\"a\")\n",
    "f.write(\"This is a new line added to the text file.\\n\")\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ffe0c0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Ali', 'age': 22, 'skills': ['python', 'sql', 'data']}\n",
      "python\n",
      "sql\n",
      "data\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "f=open('Dataset.json',\"r\")\n",
    "data=json.load(f)\n",
    "print(data)\n",
    "for i in data[\"skills\"]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c953053c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Ali', '19', 'Lahore'], ['Usman', '20', 'Islamabad'], ['Rafeeq', '18', 'Lahore']]\n",
      "Cleaned data written to Cleaned_Dataset.csv\n"
     ]
    }
   ],
   "source": [
    "cleaned=[]\n",
    "with open('Dataset.csv',\"r\")as f :\n",
    "    reader=csv.reader(f)\n",
    "    next(reader)  # Skip header row if present\n",
    "    for row in reader:\n",
    "        name=row[0].strip().capitalize()\n",
    "        age=row[1]\n",
    "        city=row[2].strip().capitalize()\n",
    "        cleaned.append([name,age,city])\n",
    "\n",
    "print(cleaned)\n",
    "\n",
    "with open('Cleaned_Dataset.csv',\"w\",newline=\"\") as f:\n",
    "    writer=csv.writer(f)\n",
    "    writer.writerow(['Name','Age','City'])\n",
    "    writer.writerows(cleaned)\n",
    "print(\"Cleaned data written to Cleaned_Dataset.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "468594cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ali\n",
      "{'name': 'Ali', 'age': 23, 'city': 'Lahore', 'profession': 'Engineer', 'skills': ['Python', 'SQL']}\n",
      "Python\n",
      "SQL\n",
      "name : Ali\n",
      "age : 23\n",
      "city : Lahore\n",
      "profession : Engineer\n",
      "skills : ['Python', 'SQL']\n"
     ]
    }
   ],
   "source": [
    "#Dictionaries\n",
    "person = {\n",
    "    \"name\": \"Ali\",\n",
    "    \"age\": 22,\n",
    "    \"city\": \"Lahore\"\n",
    "}\n",
    "\n",
    "print(person[\"name\"])\n",
    "#updatation in Dictionary\n",
    "person[\"age\"] = 23\n",
    "person[\"profession\"] = \"Engineer\"\n",
    "person[\"skills\"] = [\"Python\", \"SQL\"]\n",
    "print(person)\n",
    "for i in person[\"skills\"]:\n",
    "    print(i)\n",
    "    \n",
    "for key, value in person.items():\n",
    "    print(key, \":\", value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e78c3c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot divide by zero.\n",
      "Execution completed.\n"
     ]
    }
   ],
   "source": [
    "#Error Handling\n",
    "try:\n",
    "    num = int(input(\"Enter a number: \"))\n",
    "    print(10 / num)\n",
    "except ZeroDivisionError:\n",
    "    print(\"Cannot divide by zero.\")\n",
    "except ValueError:\n",
    "    print(\"Invalid number.\")\n",
    "finally:\n",
    "    print(\"Execution completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "835d7173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "#mini concept data transformation\n",
    "raw_age = \" 22 \"\n",
    "clean_age = int(raw_age.strip())\n",
    "print(clean_age)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4dc7c29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Ali', 22, 'Lahore'], ['Sara', 21, 'Karachi'], ['Hamza', 23, 'Islamabad']]\n",
      "Cleaned data written to Cleaned_Data.csv\n"
     ]
    }
   ],
   "source": [
    "#Mini ETL Pipeline Simulation\n",
    "\n",
    "data = [\n",
    "    {\"name\": \" ali \", \"age\": \"22\", \"city\": \" lahore \"},\n",
    "    {\"name\": \" SARA\", \"age\": \"21\", \"city\": \" KARACHI \"},\n",
    "    {\"name\": \"hamza \", \"age\": \"23\", \"city\": \" Islamabad\"}\n",
    "]\n",
    "cleaned=[]\n",
    "for row in data:\n",
    " try:\n",
    "    name=row[\"name\"].strip().capitalize()\n",
    "    age=int(row[\"age\"].strip())\n",
    "    city=row[\"city\"].strip().capitalize()\n",
    "    cleaned.append([name, age, city])\n",
    " except Exception as e:\n",
    "     print(\"Error cleaning row:\", row, \"| Error:\", e)\n",
    "#we use error handling to avoid breaking the entire process due to one bad record like missing age value or something like that\n",
    "\n",
    "\n",
    "\n",
    "print(cleaned)\n",
    "\n",
    "with open('Cleaned_Data.csv',\"w\",newline=\"\") as f:\n",
    "    writer=csv.writer(f)\n",
    "    writer.writerow(['Name','Age','City'])\n",
    "    writer.writerows(cleaned)\n",
    "print(\"Cleaned data written to Cleaned_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e8d5410c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name  Age        City\n",
      "1  USmAn   20  IslamAbad \n",
      "     Name  Age       City\n",
      "0     Ali   19     Lahore\n",
      "1   Usman   20  Islamabad\n",
      "2  Rafeeq   18     Lahore\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('Dataset.csv')\n",
    "print(df[df[\"Age\"]>19])\n",
    "\n",
    "#cleaning is easy with pandas\n",
    "\n",
    "df[\"Name\"]=df[\"Name\"].str.strip().str.capitalize()\n",
    "df[\"City\"]=df[\"City\"].str.strip().str.capitalize()\n",
    "print(df)\n",
    "df.to_csv('Cleaned_with_pandas.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb91d835",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatination two csv's\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"Cleaned_with_pandas.csv\")\n",
    "df2 = pd.read_csv(\"Cleaned_with_pandas 2.csv\")\n",
    "\n",
    "combined = pd.concat([df1, df2], ignore_index=True)\n",
    "print(combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74924ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SQL like Things\n",
    "#Merging\n",
    "df3=pd.read_csv(\"skills.csv\")\n",
    "merging=pd.merge(combined,df3,on=\"Name\",how=\"left\")\n",
    "print(merging)\n",
    "merging.to_csv(\"Final_Output.csv\",index=False)\n",
    "\n",
    "#GroupBY\n",
    "\n",
    "grouped=merging.groupby(\"City\")[\"Age\"].mean()\n",
    "print(grouped)\n",
    "\n",
    "#Sorting \n",
    "\n",
    "df_sorted = merging.sort_values(by=\"Name\")\n",
    "print(df_sorted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff79fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"city_data.csv\")\n",
    "\n",
    "# Clean\n",
    "df[\"name\"] = df[\"name\"].str.strip().str.capitalize()\n",
    "df[\"city\"] = df[\"city\"].str.strip().str.capitalize()\n",
    "\n",
    "# Group by city\n",
    "sales_by_city = df.groupby(\"city\")[\"sales\"].sum()\n",
    "\n",
    "print(\"Sales by city:\")\n",
    "print(sales_by_city)\n",
    "\n",
    "# Sort by highest sales\n",
    "sorted_sales = sales_by_city.sort_values(ascending=False)\n",
    "print(\"\\nCities ranked by sales:\")\n",
    "print(sorted_sales)\n",
    "\n",
    "# Export result\n",
    "sorted_sales.to_csv(\"city_sales_report.csv\", header=True)\n",
    "\n",
    "print(\"\\nReport generated: city_sales_report.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0b82b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"missing.csv\")\n",
    "print(df)\n",
    "print(df.isna().sum())\n",
    "#dropping Missing Row\n",
    "df_drop = df.dropna()\n",
    "#replace missing rows with a specific word\n",
    "df[\"city\"] = df[\"city\"].fillna(\"Islamabad\")\n",
    "df[\"age\"] = df[\"age\"].fillna('25')\n",
    "\n",
    "\n",
    "print(df)\n",
    "df.to_csv(\"missing.csv\",index=False)\n",
    "print(\"Missing values filled and saved to missing_filled.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "e8a97060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer data transformed successfully!\n",
      "     name     city  sales  bonus category city_code\n",
      "0     Ali   Lahore    200   20.0      Low       LHR\n",
      "1    Sara  Karachi    150   15.0      Low       KHI\n",
      "2   Hamza   Lahore    300   30.0     High       LHR\n",
      "3  Ayesha   Multan    100   10.0      Low       MLT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"salees.csv\")\n",
    "\n",
    "# Clean name & city\n",
    "df[\"name\"] = df[\"name\"].apply(lambda x: x.strip().capitalize())\n",
    "df[\"city\"] = df[\"city\"].apply(lambda x: x.strip().capitalize())\n",
    "\n",
    "# Convert sales to int\n",
    "df[\"sales\"] = df[\"sales\"].astype(int)\n",
    "\n",
    "# Bonus: 10%\n",
    "df[\"bonus\"] = df[\"sales\"] * 0.10\n",
    "\n",
    "# Category based on sales\n",
    "df[\"category\"] = df[\"sales\"].apply(lambda x: \"High\" if x > 200 else \"Low\")\n",
    "\n",
    "# Map city codes\n",
    "df[\"city_code\"] = df[\"city\"].map({\n",
    "    \"Lahore\": \"LHR\",\n",
    "    \"Karachi\": \"KHI\",\n",
    "    \"Multan\": \"MLT\"\n",
    "})\n",
    "\n",
    "df.to_csv(\"customers_transformed.csv\", index=False)\n",
    "\n",
    "print(\"Customer data transformed successfully!\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aa1155",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
